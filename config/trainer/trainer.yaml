# @package _global_

# Basic experiment settings
exp_name: "Test"
seed: 1
torch_deterministic: True
cuda: True
use_wandb: True
wandb_project_name: "Multiverse"
wandb_entity: null

# Environment settings
env_id: "PongNoFrameskip-v4"
total_steps: 10_000_000 # total number of steps to run the collection and training
steps_per_collection: 8256 # (4 * 8 * (128 + 1)) (Should be a factor of num_envs * (num_steps + 1)
num_collector_envs: 8
save_path: "training_checkpoints"
# World Model Parameters
world_models:
  - type: "iris"
    name: "iris_1"
    tokenizer: "iris/tokenizer/tokenizer_1"
    transformer: "iris/transformer/transformer_1"
    load_checkpoint: True
#  - type: "iris"
#    name: "iris_2"
#    tokenizer: "iris/tokenizer/tokenizer_1"
#    transformer: "iris/transformer/transformer_2"
#    load_checkpoint: False
#  - name: "iris_3"
#    tokenizer: "iris/tokenizer/tokenizer_2"
#    transformer: "iris/transformer/transformer_2"
#    load_checkpoint: True

# Training parameters
training:
  save_every: 10 # Save model every n iterations
  env_type: "wm" # Options: "gym", "wm"
  total_timesteps: 100_000 # Steps per training iteration
  num_steps: 128 # Number of steps to run in each environment per update (batch size = num_envs * num_steps)
  learning_rate: 2.5e-4
  anneal_lr: True

# Evaluation
eval:
  env_type: "gym" # Options: "gym", "wm"
  num_envs: 8
  eval_frequency: 1
  total_episodes: 8
  max_steps: 10_000
  save_video: False

# PPO-specific parameters
agent:
  #load_checkpoint_path: null # null for no checkpoint, example "training_checkpoints/PongNoFrameskip-v4_agent_last.pt"
  load_checkpoint_path: "training_checkpoints/gym_pretrained/PongNoFrameskip-v4_agent_last.pt"
  gamma: 0.99
  gae_lambda: 0.95
  num_minibatches: 16
  update_epochs: 16
  norm_adv: True
  clip_coef: 0.1
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: null
